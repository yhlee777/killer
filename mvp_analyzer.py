# -*- coding: utf-8 -*-
# mvp_analyzer.py - ì‹¤ì‹œê°„ í¬ë¡¤ë§ (ë¸”ë™ë¦¬ìŠ¤íŠ¸ë§Œ + ì²«ë²ˆì§¸ ì„ íƒ)

import asyncio
import sqlite3
import re
from datetime import datetime, timedelta
from playwright.async_api import async_playwright

from hybrid_insight_engine import generate_hybrid_report  # ğŸ”¥ ë³€ê²½ë¨
from review_preprocessor import (
    generate_review_stats,
    compare_review_stats,
    format_comparison_for_gpt
)
from competitor_search import find_competitors_smart, normalize_area

DB_FILE = 'seoul_industry_reviews.db'
TARGET_REVIEWS = 150
SCROLL_DEPTH = 20
MONTHS_FILTER = 12


# ==================== ë¸”ë™ë¦¬ìŠ¤íŠ¸ ====================

STORE_NAME_BLACKLIST = [
    "ì´ë¯¸ì§€ìˆ˜",
    "ì´ë¯¸ì§€",
    "ì‚¬ì§„",
    "ë©”ë‰´",
    "ë¦¬ë·°",
    "ë”ë³´ê¸°",
    "ìƒì„¸ë³´ê¸°",
    "ì •ë³´",
    "ì•ˆë‚´",
    "ê´‘ê³ ",
]


def is_blacklisted(store_name):
    """ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì²´í¬"""
    if not store_name:
        return True
    
    name_lower = store_name.lower().strip()
    
    for blacklist_item in STORE_NAME_BLACKLIST:
        if name_lower == blacklist_item.lower():
            return True
        if len(blacklist_item) >= 3 and blacklist_item.lower() in name_lower:
            return True
    
    return False


async def select_best_store(store_items, user_input, debug=True):
    """
    ê°€ê²Œ ëª©ë¡ì—ì„œ ìµœì ì˜ ê°€ê²Œ ì„ íƒ (ê°„ì†Œí™” ë²„ì „)
    
    ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì œê±° í›„ ì²« ë²ˆì§¸ ê°€ê²Œ ì„ íƒ
    """
    if not store_items:
        return None, None
    
    if debug:
        print(f"\n   ğŸ” ê°€ê²Œ ì„ íƒ ì¤‘... (ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„°ë§)")
    
    for idx, item in enumerate(store_items[:10], 1):
        try:
            text = await item.inner_text(timeout=500)
            if not text or not text.strip():
                continue
            
            lines = [ln.strip() for ln in text.split('\n') if ln.strip()]
            if not lines:
                continue
            
            store_name = lines[0]
            
            # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì²´í¬
            if is_blacklisted(store_name):
                if debug:
                    print(f"      [{idx}] âŒ ë¸”ë™ë¦¬ìŠ¤íŠ¸: {store_name}")
                continue
            
            # ğŸ”¥ ì²« ë²ˆì§¸ ìœ íš¨í•œ ê°€ê²Œ ì„ íƒ!
            if debug:
                print(f"      [{idx}] âœ… ì„ íƒ: {store_name}")
            
            return item, store_name
        
        except Exception as e:
            if debug:
                print(f"      [{idx}] âš ï¸  íŒŒì‹± ì‹¤íŒ¨: {e}")
            continue
    
    # ëª¨ë“  ê°€ê²Œê°€ ë¸”ë™ë¦¬ìŠ¤íŠ¸ë©´ None
    if debug:
        print(f"      âŒ ìœ íš¨í•œ ê°€ê²Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
    
    return None, None


# ==================== ì—…ì¢… ì¶”ì¶œ (ê°œì„ ) ====================

def extract_category_from_text(text, store_name):
    """
    í…ìŠ¤íŠ¸ì—ì„œ ì—…ì¢… ì¶”ì¶œ (ê°•í™” ë²„ì „)
    
    ì „ëµ:
    1. ê°€ê²Œëª…ì—ì„œ ì§ì ‘ ì¶”ì¶œ (ìµœìš°ì„ !)
    2. í™•ì¥ëœ í‚¤ì›Œë“œ ë§¤ì¹­
    3. í´ë°±: "ìŒì‹ì "
    """
    if not text:
        return "ìŒì‹ì "
    
    # ğŸ”¥ ì „ëµ 1: ê°€ê²Œëª…ì—ì„œ ì§ì ‘ ì¶”ì¶œ (ìµœìš°ì„ !)
    if store_name:
        # í‚¤ì›Œë“œ ìš°ì„ ìˆœìœ„: êµ¬ì²´ì  â†’ ì¼ë°˜ ìˆœ
        # "ìš”ë¦¬ì£¼ì "ì„ ê·¸ëŒ€ë¡œ ìœ ì§€! (ì •ì œí•˜ì§€ ì•ŠìŒ)
        for keyword in ['ìš”ë¦¬ì£¼ì ', 'ì˜¤ë§ˆì¹´ì„¸', 'ìŠ¤ì‹œ', 'ì´ìì¹´ì•¼', 'ë¼ë©˜', 
                       'ëˆì¹´ì¸ ', 'ìƒ¤ë¸Œìƒ¤ë¸Œ', 'ë·”í˜', 'ë² ì´ì»¤ë¦¬', 
                       'ì£¼ì ', 'ìˆ ì§‘', 'ì¹´í˜', 'ìŒì‹ì ', 'ì‹ë‹¹', 
                       'ì¼ì‹', 'ì–‘ì‹', 'ì¤‘ì‹', 'í•œì‹', 'ì¹˜í‚¨', 'í”¼ì']:
            if keyword in store_name:
                # "ìš”ë¦¬"ë¡œ ëë‚˜ëŠ” ê²½ìš°ë§Œ ì •ì œ (ì˜ˆ: "ìœ¡ë¥˜ìš”ë¦¬" â†’ "ìœ¡ë¥˜")
                if keyword.endswith('ìš”ë¦¬') and keyword != 'ìš”ë¦¬ì£¼ì ':
                    return keyword[:-2]
                return keyword  # ìš”ë¦¬ì£¼ì ì€ ê·¸ëŒ€ë¡œ ë°˜í™˜!
    
    # ê°€ê²Œëª… ì œê±° (ì „ëµ 2ë¥¼ ìœ„í•´)
    text_clean = text.replace(store_name, '') if store_name else text
    
    # ğŸ”¥ í™•ì¥ëœ ì—…ì¢… í‚¤ì›Œë“œ (ìš°ì„ ìˆœìœ„ ìˆœ)
    industry_keywords = [
        # êµ¬ì²´ì  ì¹´í…Œê³ ë¦¬ ìš°ì„ 
        'ìš”ë¦¬ì£¼ì ', 'ì˜¤ë§ˆì¹´ì„¸', 'ìŠ¤ì‹œ', 'ì´ìì¹´ì•¼', 'ë¼ë©˜', 'ìš°ë™', 'ëˆì¹´ì¸ ',
        'íŒŒìŠ¤íƒ€', 'ì´íƒˆë¦¬ì•ˆ', 'ìŠ¤í…Œì´í¬', 'í”¼ì',
        'ë””ì €íŠ¸ì¹´í˜', 'ë¸ŒëŸ°ì¹˜ì¹´í˜', 'ë² ì´ì»¤ë¦¬',
        'ì™€ì¸ë°”', 'ì¹µí…Œì¼ë°”', 'í',
        'ì•„ê·€ì°œ', 'í•´ë¬¼ì°œ', 'ê°ˆë¹„', 'ì‚¼ê²¹ì‚´', 'ê³±ì°½', 'ìœ¡ë¥˜',
        'ë§ˆë¼íƒ•', 'ë”¤ì„¬', 'ìŒ€êµ­ìˆ˜',
        'ìƒ¤ë¸Œìƒ¤ë¸Œ', 'ë·”í˜',
        # ì¼ë°˜ ì¹´í…Œê³ ë¦¬
        'ì£¼ì ', 'ìˆ ì§‘', 'ì¹´í˜', 'ì¼ì‹', 'ì–‘ì‹', 'ì¤‘ì‹', 'í•œì‹',
    ]
    
    # í‚¤ì›Œë“œ ë§¤ì¹­
    for keyword in industry_keywords:
        if keyword in text_clean:
            # "ìš”ë¦¬"ë¡œ ëë‚˜ëŠ” ê²½ìš°ë§Œ ì •ì œ
            if keyword.endswith('ìš”ë¦¬') and keyword != 'ìš”ë¦¬ì£¼ì ':
                return keyword[:-2]
            return keyword
    
    # ëª» ì°¾ìœ¼ë©´ í´ë°±
    return "ìŒì‹ì "


async def extract_category_from_page(page, store_name):
    """
    í˜ì´ì§€ì—ì„œ ì—…ì¢… ì¶”ì¶œ (3ë‹¨ê³„ ì „ëµ)
    """
    try:
        # ğŸ”¥ ìµœìš°ì„ : ê°€ê²Œëª…ì—ì„œ ì§ì ‘ ì¶”ì¶œ
        print(f"   ğŸ” ì—…ì¢… ì¶”ì¶œ ì‹œë„: ê°€ê²Œëª…='{store_name}'")
        
        if store_name:
            result = extract_category_from_text(store_name, store_name)
            if result != "ìŒì‹ì ":
                print(f"   âœ… ê°€ê²Œëª…ì—ì„œ ì¶”ì¶œ: {result}")
                return result
        
        # ğŸ”¥ ì „ëµ 1: span.lnJFt CSS ì…€ë ‰í„°
        try:
            category_element = await page.locator('span.lnJFt').first
            if category_element:
                text = await category_element.inner_text(timeout=2000)
                if text and text != store_name:
                    result = extract_category_from_text(text, store_name)
                    if result != "ìŒì‹ì ":
                        print(f"   âœ… CSS ì…€ë ‰í„°ì—ì„œ ì¶”ì¶œ: {result}")
                        return result
        except:
            pass
        
        # ğŸ”¥ ì „ëµ 2: í…ìŠ¤íŠ¸ íŒ¨í„´ "{ê°€ê²Œëª…}{ì¹´í…Œê³ ë¦¬}"
        try:
            body_text = await page.inner_text('body', timeout=3000)
            lines = [ln.strip() for ln in body_text.split('\n') if ln.strip()]
            
            for line in lines[:20]:
                if store_name in line:
                    remainder = line.replace(store_name, '').strip()
                    if remainder and len(remainder) < 30:
                        result = extract_category_from_text(remainder, store_name)
                        if result != "ìŒì‹ì ":
                            print(f"   âœ… í…ìŠ¤íŠ¸ íŒ¨í„´ì—ì„œ ì¶”ì¶œ: {result} (from: '{line[:50]}...')")
                            return result
        except:
            pass
        
        # ğŸ”¥ ì „ëµ 3: í˜ì´ì§€ ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰
        try:
            body_text = await page.inner_text('body', timeout=3000)
            result = extract_category_from_text(body_text[:2000], store_name)
            print(f"   âš ï¸  í˜ì´ì§€ ì „ì²´ ê²€ìƒ‰: {result}")
            return result
        except:
            pass
        
        print(f"   âš ï¸  ì—…ì¢… ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: ìŒì‹ì ")
        return "ìŒì‹ì "
        
    except:
        print(f"   âŒ ì—…ì¢… ì¶”ì¶œ ì˜¤ë¥˜, ê¸°ë³¸ê°’ ì‚¬ìš©: ìŒì‹ì ")
        return "ìŒì‹ì "


# ==================== ì£¼ì†Œ íŒŒì‹± ====================

def extract_dong_from_address(address):
    """
    ì£¼ì†Œì—ì„œ ë™ ë‹¨ìœ„ ì¶”ì¶œ (ê°œì„ )
    
    "ì„±ìˆ˜", "ê°•ë‚¨ì—­", "í™ëŒ€" ê°™ì€ ì§§ì€ ì…ë ¥ë„ ì²˜ë¦¬
    """
    if not address:
        return None
    
    # 1. ì—­ëª…/ì§€ì—­ëª… ë§¤í•‘ í™œìš© (STATION_TO_AREA)
    normalized = normalize_area(address)
    if normalized and normalized != address:
        return normalized
    
    # 2. ì •ê·œì‹ íŒ¨í„´ ë§¤ì¹­
    # "OOêµ¬ OOë™" íŒ¨í„´
    gu_dong_match = re.search(r'[ê°€-í£]+êµ¬\s+([ê°€-í£]+ë™)', address)
    if gu_dong_match:
        return gu_dong_match.group(1)
    
    # "OOë™" íŒ¨í„´
    dong_match = re.search(r'([ê°€-í£]+ë™)(?![ê°€-í£])', address)
    if dong_match:
        return dong_match.group(1)
    
    # "OOêµ¬" íŒ¨í„´
    gu_match = re.search(r'([ê°€-í£]+êµ¬)', address)
    if gu_match:
        return gu_match.group(1)
    
    # 3. "ë™" ë¶™ì—¬ì„œ ì¬ì‹œë„ (ì„±ìˆ˜ â†’ ì„±ìˆ˜ë™)
    if not address.endswith('ë™') and not address.endswith('êµ¬') and not address.endswith('ì—­'):
        candidate = address + 'ë™'
        normalized = normalize_area(candidate)
        if normalized and normalized != candidate:
            return normalized
    
    # 4. ëª» ì°¾ìœ¼ë©´ ì›ë³¸ ë°˜í™˜ (ì—ëŸ¬ ëŒ€ì‹ )
    return address


# ==================== í¬ë¡¤ë§ í—¬í¼ ====================

def is_owner_reply(review_text):
    """ì‚¬ì¥ë‹˜ ë‹µê¸€ í•„í„°ë§"""
    if not review_text:
        return False
    strong_signals = ['ë¦¬ë·° ê°ì‚¬', 'ì§„ì‹¬ìœ¼ë¡œ ê°ì‚¬', 'ì°¾ì•„ì£¼ì…”ì„œ', 'ë³´ë‹µí•˜ê² ìŠµë‹ˆë‹¤']
    return any(s in review_text for s in strong_signals) or \
           sum(1 for k in ['ê°ì‚¬ë“œë¦½ë‹ˆë‹¤', 'ê°ì‚¬í•©ë‹ˆë‹¤'] if k in review_text) >= 2


async def expand_reviews(page):
    """'í¼ì³ì„œ ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­"""
    try:
        await page.evaluate("""
            () => {
                document.querySelectorAll('button, a').forEach(btn => {
                    if (btn.textContent.includes('í¼ì³ì„œ ë”ë³´ê¸°')) {
                        try { btn.click(); } catch(e) {}
                    }
                });
            }
        """)
    except:
        pass


# ==================== ì‹¤ì‹œê°„ í¬ë¡¤ë§ ====================

async def crawl_store_info(store_name, region_hint=None):
    """ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ í¬ë¡¤ë§ (ë¸”ë™ë¦¬ìŠ¤íŠ¸ + ì²«ë²ˆì§¸ ì„ íƒ)"""
    print(f"\n{'='*60}")
    print(f"ğŸ” STEP 1: '{store_name}' ì‹¤ì‹œê°„ í¬ë¡¤ë§")
    print(f"{'='*60}")
    
    if region_hint:
        print(f"   ğŸ’¡ ì‚¬ìš©ì ì…ë ¥ ì§€ì—­: {region_hint}")
    
    async with async_playwright() as playwright:
        browser = await playwright.chromium.launch(
            headless=False,
            args=['--disable-blink-features=AutomationControlled']
        )
        context = await browser.new_context(
            viewport={"width": 1920, "height": 1080},
            locale="ko-KR"
        )
        await context.add_init_script(
            "Object.defineProperty(navigator, 'webdriver', { get: () => undefined });"
        )
        page = await context.new_page()
        
        try:
            # 1. ë„¤ì´ë²„ ì§€ë„ ê²€ìƒ‰
            search_url = f"https://map.naver.com/v5/search/{store_name}"
            await page.goto(search_url, wait_until="domcontentloaded", timeout=30000)
            await asyncio.sleep(3)
            
            # 2. ê²€ìƒ‰ í”„ë ˆì„ ì°¾ê¸°
            search_frame = None
            for attempt in range(15):
                for frame in page.frames:
                    if "searchIframe" in frame.name or "entry=plt" in frame.url:
                        search_frame = frame
                        break
                if search_frame:
                    break
                await asyncio.sleep(1)
            
            if not search_frame:
                print("   âŒ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                await context.close()
                await browser.close()
                return None
            
            await asyncio.sleep(3)
            
            # 3. ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘
            store_items = []
            
            selectors = [
                "li.UEzoS",
                "li.CHC5F",
                "li[data-id]",
                "li.Efc51",
                "li.tzwk0",
                "div.place_bluelink",
                "a[class*='place']",
            ]
            
            for sel in selectors:
                try:
                    items = await search_frame.locator(sel).all()
                    if not items:
                        continue
                    
                    print(f"   ğŸ” ì…€ë ‰í„° '{sel}': {len(items)}ê°œ ë°œê²¬")
                    
                    valid_items = []
                    for item in items[:10]:
                        try:
                            text = await item.inner_text(timeout=500)
                            if text and text.strip():
                                valid_items.append(item)
                        except:
                            pass
                    
                    if len(valid_items) >= 1:
                        store_items = valid_items
                        print(f"   âœ… {len(valid_items)}ê°œ ìœ íš¨ í•­ëª© ë°œê²¬")
                        break
                except Exception as e:
                    print(f"   âš ï¸  ì…€ë ‰í„° '{sel}' ì‹¤íŒ¨: {e}")
                    pass
            
            if not store_items:
                print("   âŒ ê°€ê²Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                await context.close()
                await browser.close()
                return None
            
            # ğŸ”¥ ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„° + ì²« ë²ˆì§¸ ì„ íƒ
            best_store, store_name_found = await select_best_store(
                store_items, 
                store_name,
                debug=True
            )
            
            if not best_store:
                print("   âŒ ì í•©í•œ ê°€ê²Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                await context.close()
                await browser.close()
                return None
            
            await asyncio.sleep(1)
            await best_store.click(timeout=3000)
            await asyncio.sleep(3)
            
            # 4. place_id ì¶”ì¶œ
            place_id = None
            for frame in page.frames:
                match = re.search(r'place[/=](\d+)', frame.url)
                if match:
                    place_id = match.group(1)
                    break
            
            if not place_id:
                print("   âŒ place_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                await context.close()
                await browser.close()
                return None
            
            print(f"\n   âœ… ê°€ê²Œëª…: {store_name} (ì‚¬ìš©ì ì…ë ¥)")
            print(f"   âœ… í¬ë¡¤ë§ ê°€ê²Œëª…: {store_name_found}")
            print(f"   âœ… Place ID: {place_id}")
            
            # 5. ìƒì„¸ í˜ì´ì§€ë¡œ ì´ë™
            detail_url = f"https://m.place.naver.com/restaurant/{place_id}/home"
            await page.goto(detail_url, wait_until="domcontentloaded", timeout=30000)
            await asyncio.sleep(2)
            
            # ì§€ì—­ ì¶”ì¶œ
            if region_hint:
                region = region_hint
                print(f"   âœ… ì§€ì—­: {region} (ì‚¬ìš©ì ì…ë ¥)")
            else:
                region = "ì•Œ ìˆ˜ ì—†ìŒ"
                try:
                    page_text = await page.inner_text("body", timeout=3000)
                    dong_match = re.search(r'ì„œìš¸íŠ¹?ë³„?ì‹œ?\s+[ê°€-í£]+êµ¬\s+([ê°€-í£]+ë™)', page_text)
                    if dong_match:
                        region = dong_match.group(1)
                    else:
                        gu_match = re.search(r'ì„œìš¸íŠ¹?ë³„?ì‹œ?\s+([ê°€-í£]+êµ¬)', page_text)
                        if gu_match:
                            region = gu_match.group(1)
                    print(f"   âœ… ì§€ì—­: {region} (í¬ë¡¤ë§ ì¶”ì¶œ)")
                except:
                    print(f"   âš ï¸  ì§€ì—­: {region}")
            
            # ğŸ”¥ ì—…ì¢… ì¶”ì¶œ (ê°œì„ !)
            industry = await extract_category_from_page(page, store_name_found)
            print(f"   âœ… ì—…ì¢…: {industry}")
            
            # 6. ë¦¬ë·° í˜ì´ì§€ë¡œ ì´ë™
            print(f"\n{'='*60}")
            print(f"ğŸ“¥ STEP 2: ë¦¬ë·° ìˆ˜ì§‘ (ëª©í‘œ: {TARGET_REVIEWS}ê°œ)")
            print(f"{'='*60}")
            
            review_url = f"https://m.place.naver.com/restaurant/{place_id}/review/visitor"
            await page.goto(review_url, wait_until="domcontentloaded", timeout=30000)
            await asyncio.sleep(2)
            
            # ìµœì‹ ìˆœ ì •ë ¬
            print("   ğŸ”„ ìµœì‹ ìˆœ ì •ë ¬ ì¤‘...")
            try:
                for selector in ["button:has-text('ìµœì‹ ìˆœ')", "a:has-text('ìµœì‹ ìˆœ')"]:
                    try:
                        await page.click(selector, timeout=3000)
                        print("   âœ… ìµœì‹ ìˆœ ì •ë ¬ ì™„ë£Œ")
                        await asyncio.sleep(2)
                        break
                    except:
                        continue
            except:
                print("   âš ï¸  ìµœì‹ ìˆœ ë²„íŠ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
            # 7. ìŠ¤í¬ë¡¤ & ë¦¬ë·° ìˆ˜ì§‘
            print("   â¬ ìŠ¤í¬ë¡¤ ì¤‘...")
            for i in range(30):
                try:
                    await page.evaluate("window.scrollBy(0, 2000)")
                except:
                    pass
                await asyncio.sleep(0.3)
                await expand_reviews(page)
                
                if i % 10 == 0:
                    count = 0
                    for sel in ["li.place_apply_pui", "li.pui__X35jYm"]:
                        try:
                            count = await page.locator(sel).count()
                            if count >= TARGET_REVIEWS:
                                print(f"   âœ… {count}ê°œ ë°œê²¬, ìˆ˜ì§‘ ì¤‘ë‹¨")
                                break
                        except:
                            pass
                    if count >= TARGET_REVIEWS:
                        break
            
            # 8. ë¦¬ë·° íŒŒì‹±
            reviews = []
            review_items = []
            for sel in ["li.place_apply_pui", "li.pui__X35jYm", "li.EjjAW"]:
                try:
                    items = await page.locator(sel).all()
                    if items:
                        review_items = items
                        break
                except:
                    pass
            
            print(f"   ğŸ“ íŒŒì‹± ì¤‘... (ë°œê²¬: {len(review_items)}ê°œ)")
            
            for item in review_items[:TARGET_REVIEWS + 20]:
                try:
                    full_text = await item.inner_text(timeout=500)
                    if len(full_text) < 50:
                        continue
                    
                    review = {"ë³„ì ": None, "ë‚ ì§œ": None, "ë¦¬ë·°": ""}
                    
                    if 'â˜…' in full_text:
                        review["ë³„ì "] = float(min(full_text.count('â˜…'), 5))
                    
                    date_patterns = [
                        r'(\d{4}[./-]\d{1,2}[./-]\d{1,2})',
                        r'(\d{1,2}[./-]\d{1,2})',
                        r'(\d+ì¼\s*ì „)',
                    ]
                    
                    for pattern in date_patterns:
                        date_match = re.search(pattern, full_text)
                        if date_match:
                            review["ë‚ ì§œ"] = date_match.group(1)
                            break
                    
                    lines = [ln.strip() for ln in full_text.split('\n') if len(ln.strip()) >= 20]
                    if lines:
                        review["ë¦¬ë·°"] = max(lines, key=len)
                    
                    if review["ë¦¬ë·°"] and not is_owner_reply(review["ë¦¬ë·°"]):
                        reviews.append(review)
                    
                    if len(reviews) >= TARGET_REVIEWS:
                        break
                        
                except:
                    pass
            
            print(f"   âœ… ìˆ˜ì§‘ëœ ë¦¬ë·°: {len(reviews)}ê°œ")
            
            await context.close()
            await browser.close()
            
            return {
                'place_id': place_id,
                'name': store_name,
                'district': region,
                'industry': industry,
                'reviews': reviews
            }
            
        except Exception as e:
            print(f"   âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            await context.close()
            await browser.close()
            return None


# ==================== DB ê´€ë ¨ ====================

def parse_review_date(date_str):
    """ë‚ ì§œ ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ ë³€í™˜"""
    if not date_str:
        return None
    
    try:
        date_str = date_str.replace('/', '.').replace('-', '.')
        parts = date_str.split('.')
        if len(parts) == 3:
            year, month, day = int(parts[0]), int(parts[1]), int(parts[2])
            return datetime(year, month, day)
    except:
        pass
    
    return None


def is_recent_review(date_str, months=6):
    """ìµœê·¼ Nê°œì›” ì´ë‚´ ë¦¬ë·°ì¸ì§€ í™•ì¸"""
    review_date = parse_review_date(date_str)
    if not review_date:
        return True
    
    cutoff_date = datetime.now() - timedelta(days=months * 30)
    return review_date >= cutoff_date


def get_reviews_from_db(place_id, filter_recent=True):
    """DBì—ì„œ ë¦¬ë·° ê°€ì ¸ì˜¤ê¸°"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute("SELECT date, content FROM reviews WHERE place_id = ?", (place_id,))
    all_reviews = cursor.fetchall()
    conn.close()
    
    reviews = []
    for date_str, content in all_reviews:
        if not content or not content.strip():
            continue
        
        if filter_recent:
            if is_recent_review(date_str, MONTHS_FILTER):
                reviews.append({'date': date_str if date_str else 'ë‚ ì§œì—†ìŒ', 
                              'content': content.strip()})
        else:
            reviews.append({'date': date_str if date_str else 'ë‚ ì§œì—†ìŒ', 
                          'content': content.strip()})
    
    return reviews


# ==================== ë©”ì¸ ====================

async def main():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   ğŸª ë§›ì§‘ ì‹¤ì‹œê°„ ë¶„ì„ ì‹œìŠ¤í…œ                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    store_input = input("\nê°€ê²Œ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    if not store_input:
        print("âŒ ê°€ê²Œ ì´ë¦„ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    address_input = input("ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ê°•ë‚¨ì—­, ì„±ìˆ˜ë™, ì„±ìˆ˜, í™ëŒ€): ").strip()
    if not address_input:
        print("âŒ ì£¼ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    region_extracted = extract_dong_from_address(address_input)
    
    print(f"\nâœ… ì¶”ì¶œëœ ì§€ì—­: {region_extracted}")
    
    # ğŸ”¥ ë¸”ë¡œê·¸ ë¶„ì„ ì„ íƒ ì¶”ê°€
    blog_profile = None  # ê¸°ë³¸ê°’
    do_blog = input("\në¸”ë¡œê·¸ ë¶„ì„ë„ í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N, 20ì´ˆ ì†Œìš”): ").strip().lower()
    
    if do_blog == 'y':
        try:
            from naver_blog_crawler import analyze_store_from_blog
            print(f"\n{'='*60}")
            print(f"ğŸ“± ë¸”ë¡œê·¸ ë¶„ì„ ì¤‘...")
            print(f"{'='*60}")
            blog_profile = analyze_store_from_blog(store_input)
            print(f"   âœ… ë¸”ë¡œê·¸ {blog_profile.total_blog_posts}ê°œ ë¶„ì„ ì™„ë£Œ")
            print(f"   ê¸ì • ë¹„ìœ¨: {blog_profile.positive_ratio:.1%}")
        except Exception as e:
            print(f"   âš ï¸ ë¸”ë¡œê·¸ ë¶„ì„ ì‹¤íŒ¨ (ìŠ¤í‚µ): {e}")
    else:
        print(f"   â­ï¸  ë¸”ë¡œê·¸ ë¶„ì„ ìŠ¤í‚µ")
    
    # ğŸ¯ ê²½ìŸì‚¬ ê²€ìƒ‰ ì „ëµ ì„ íƒ
    print(f"\n{'='*60}")
    print(f"ğŸ¯ ê²½ìŸì‚¬ ê²€ìƒ‰ ì „ëµ ì„ íƒ")
    print(f"{'='*60}")
    print("\nì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ê²½ìŸì‚¬ë¥¼ ì°¾ì„ê¹Œìš”?\n")
    print("1ï¸âƒ£  ì—…ì¢… ìš°ì„  (ê°™ì€ ì—…ì¢…, ì§€ì—­ ë¬´ê´€)")
    print("    ğŸ’¡ ì¶”ì²œ: íŠ¹í™” ë©”ë‰´ê°€ ìˆê±°ë‚˜, ì§€ì—­ë³´ë‹¤ ì—…ì¢…ì´ ì¤‘ìš”í•œ ê²½ìš°")
    print("    ì˜ˆ: ì„œìš¸ ì „ì—­ì˜ ì•„ê·€ì°œ/í•´ë¬¼ì°œ ê°€ê²Œ")
    print("    Î²=2.5 (ì—…ì¢… ê°•ì¡°), Î±=0.5 (ì§€ì—­ ì•½í™”)")
    print()
    print("2ï¸âƒ£  ì§€ì—­ ìš°ì„  (ê°™ì€ ì§€ì—­, ì—…ì¢… ë‹¤ì–‘)")
    print("    ğŸ’¡ ì¶”ì²œ: ì§€ì—­ ìƒê¶Œì´ ì¤‘ìš”í•˜ê±°ë‚˜, ì—…ì¢…ë³´ë‹¤ ìœ„ì¹˜ê°€ ì¤‘ìš”í•œ ê²½ìš°")
    print("    ì˜ˆ: ë°©ì´ë™/ì†¡íŒŒê¶Œì˜ í•œì‹/ì¤‘ì‹/ì¼ì‹ ë“±")
    print("    Î²=1.0 (ì—…ì¢… ì•½í™”), Î±=1.5 (ì§€ì—­ ê°•ì¡°)")
    print()
    print("3ï¸âƒ£  ê· í˜• (ì—…ì¢…ê³¼ ì§€ì—­ ëª¨ë‘ ê³ ë ¤) â­ ì¶”ì²œ")
    print("    ğŸ’¡ ì¶”ì²œ: ëŒ€ë¶€ë¶„ì˜ ê²½ìš° (ê°€ì¥ ë¬´ë‚œ)")
    print("    ì˜ˆ: ì†¡íŒŒê¶Œì˜ ì°œ/íƒ• ìš”ë¦¬, ì„œìš¸ ì „ì—­ì˜ ì•„ê·€ì°œ")
    print("    Î²=1.8 (ì—…ì¢… ì¤‘ì‹œ), Î±=0.9 (ì§€ì—­ ë³´í†µ)")
    print()
    
    while True:
        strategy = input("ì„ íƒí•˜ì„¸ìš” (1/2/3, ê¸°ë³¸ê°’=3): ").strip()
        if strategy == '':
            strategy = '3'
        if strategy == '1':
            beta, alpha = 2.5, 0.5
            strategy_name = "ì—…ì¢… ìš°ì„ "
            break
        elif strategy == '2':
            beta, alpha = 1.0, 1.5
            strategy_name = "ì§€ì—­ ìš°ì„ "
            break
        elif strategy == '3':
            beta, alpha = 1.8, 0.9
            strategy_name = "ê· í˜•"
            break
        else:
            print("âŒ 1, 2, 3 ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
    
    print(f"\nâœ… ì„ íƒëœ ì „ëµ: {strategy_name} (Î²={beta}, Î±={alpha})")
    
    store_data = await crawl_store_info(store_input, region_hint=region_extracted)
    
    if not store_data:
        print("\nâŒ í¬ë¡¤ë§ ì‹¤íŒ¨")
        return
    
    target_store = {
        'place_id': store_data['place_id'],
        'name': store_data['name'],
        'district': region_extracted,
        'industry': store_data['industry']
    }
    
    target_reviews = store_data['reviews']
    
    if not target_reviews:
        print("\nâš ï¸  ë¦¬ë·° ì—†ìŒ")
        return
    
    print(f"\n{'='*60}")
    print(f"ğŸª STEP 3: DBì—ì„œ ê²½ìŸì‚¬ ê²€ìƒ‰")
    print(f"{'='*60}")
    
    competitors = find_competitors_smart(
        db_path=DB_FILE,
        user_area=region_extracted,
        user_industry=store_data['industry'],
        limit=5,
        beta=beta,
        alpha=alpha
    )
    
    competitor_reviews = {}
    if competitors:
        print(f"\n{'='*60}")
        print(f"ğŸ“¥ STEP 3-2: ê²½ìŸì‚¬ ë¦¬ë·° ë¡œë“œ")
        print(f"{'='*60}")
        for comp in competitors:
            reviews = get_reviews_from_db(comp.place_id)
            competitor_reviews[comp.place_id] = reviews
            print(f"   âœ… {comp.name}: {len(reviews)}ê°œ")
    
    unified_reviews = []
    for r in target_reviews:
        unified_reviews.append({
            'date': r.get('ë‚ ì§œ', 'ë‚ ì§œì—†ìŒ'),
            'content': r.get('ë¦¬ë·°', ''),
            'rating': r.get('ë³„ì ', 0)  # ğŸ”¥ rating í•„ë“œ ì¶”ê°€
        })
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š STEP 4: í†µê³„ ë¶„ì„")
    print(f"{'='*60}")
    
    our_stats = generate_review_stats(unified_reviews, target_store['name'])
    print(f"   âœ… ìš°ë¦¬ ê°€ê²Œ í†µê³„ ìƒì„± ì™„ë£Œ")
    
    comp_stats_list = []
    if competitors:
        for comp in competitors:
            comp_revs = competitor_reviews.get(comp.place_id, [])
            if comp_revs:
                comp_stat = generate_review_stats(comp_revs, comp.name)
                comp_stats_list.append(comp_stat)
        print(f"   âœ… ê²½ìŸì‚¬ í†µê³„ ìƒì„± ì™„ë£Œ")
    
    comparison_result = None
    if comp_stats_list:
        comparison_result = compare_review_stats(our_stats, comp_stats_list)
        print(f"   âœ… í†µê³„ ë¹„êµ ì™„ë£Œ")
    
    # ğŸ”¥ ì˜¬ì¸ì› HTML ë¦¬í¬íŠ¸ ìƒì„±
    from all_in_one_html import generate_all_in_one_report
    
    report = await generate_all_in_one_report(
        target_store=target_store,
        target_reviews=unified_reviews,
        blog_profile=blog_profile,  # âœ… ì´ì œ ì •ì˜ë¨!
        competitors=competitors,
        competitor_reviews=competitor_reviews,
        statistical_comparison=comparison_result
    )
    
    if report:
        print("\n" + "="*60)
        print("âœ… ì˜¬ì¸ì› HTML ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ’¡ ë¸Œë¼ìš°ì €ë¡œ ì—´ì–´ì„œ í™•ì¸í•˜ì„¸ìš”!")
        print("="*60)
    else:
        print("\nâŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨")
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   âœ… ë¶„ì„ ì™„ë£Œ!                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")


if __name__ == "__main__":
    asyncio.run(main())