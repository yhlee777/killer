# -*- coding: utf-8 -*-
# naver_blog_crawler.py - ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ë¡¤ë§ + ê°€ê²Œ ë¶„ì„ (200ê°œ ìˆ˜ì§‘)

import requests
import json
import time
from bs4 import BeautifulSoup
from typing import List, Dict, Optional
from dataclasses import dataclass
from collections import Counter
import re
from datetime import datetime

# ==================== ë„¤ì´ë²„ API ì„¤ì • ====================

NAVER_CLIENT_ID = "ZLPHHehmKYVHcF2hUGhQ"  # ë„¤ì´ë²„ ê°œë°œìì„¼í„°ì—ì„œ ë°œê¸‰
NAVER_CLIENT_SECRET = "NrVaQLeDfV"


# ==================== ë°ì´í„° í´ë˜ìŠ¤ ====================

@dataclass
class BlogPost:
    """ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸"""
    title: str
    link: str
    description: str
    blogger_name: str
    post_date: str
    
    # ì¶”ì¶œëœ ì •ë³´
    keywords: List[str]
    sentiment: str  # "ê¸ì •", "ì¤‘ë¦½", "ë¶€ì •"
    visit_purpose: Optional[str]  # "ë°ì´íŠ¸", "ì¹œëª©", "í˜¼ìˆ " ë“±
    price_mentioned: Optional[int]
    menu_mentioned: List[str]


@dataclass
class StoreProfile:
    """ê°€ê²Œ í”„ë¡œí•„ (ë¸”ë¡œê·¸ì—ì„œ ìë™ ì¶”ì¶œ)"""
    name: str
    
    # ìë™ ì¶”ì¶œëœ ì •ë³´
    industry: str  # "ìš”ë¦¬ì£¼ì ", "ì´ìì¹´ì•¼", "ì¹´í˜" ë“±
    area: str  # "ê±´ëŒ€", "í™ëŒ€" ë“±
    concept: str  # "í—ŒíŒ…í¬ì°¨", "í˜¼ìˆ ì§‘", "ë°ì´íŠ¸" ë“±
    
    # ìƒì„¸ ë¶„ì„
    target_customers: List[str]  # ["20ëŒ€", "ëŒ€í•™ìƒ", "ì»¤í”Œ"]
    signature_menus: List[str]  # ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´
    price_range: str  # "1-2ë§Œì›ëŒ€", "3-5ë§Œì›ëŒ€"
    atmosphere_keywords: List[str]  # ["ì‹œë„ëŸ¬ì›€", "ì•„ëŠ‘í•¨", "ë„“ìŒ"]
    visit_purposes: Dict[str, int]  # {"ë°ì´íŠ¸": 15, "ì¹œëª©": 30}
    
    # ìƒê¶Œ ë¶„ì„
    peak_times: List[str]  # ["ê¸ˆìš”ì¼ ì €ë…", "ì£¼ë§"]
    foot_traffic: str  # "ìƒ", "ì¤‘", "í•˜"
    competition_level: str  # "ë†’ìŒ", "ë³´í†µ", "ë‚®ìŒ"
    
    # í†µê³„
    total_blog_posts: int
    positive_ratio: float
    avg_rating: float


# ==================== ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ (200ê°œ ìˆ˜ì§‘) ====================

def search_naver_blog(query: str, total_count: int = 200) -> List[Dict]:
    """
    ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ API (ìµœëŒ€ 200ê°œ, ì¤‘ë³µ ì œê±°)
    
    Args:
        query: ê²€ìƒ‰ì–´ (ê°€ê²Œëª…)
        total_count: ê°€ì ¸ì˜¬ ì´ ê°œìˆ˜ (ê¸°ë³¸ 200ê°œ)
    
    Returns:
        ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ (ì¤‘ë³µ ì œê±°ë¨)
    """
    url = "https://openapi.naver.com/v1/search/blog.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    
    all_blogs = []
    seen_links = set()  # ì¤‘ë³µ ì œê±°ìš©
    
    # 1ë‹¨ê³„: ì²« ìš”ì²­ìœ¼ë¡œ ì „ì²´ ê°œìˆ˜ í™•ì¸
    params = {
        "query": query,
        "display": 1,
        "sort": "sim"
    }
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        available_total = data.get("total", 0)
        
        print(f"   ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: ì´ {available_total:,}ê°œ ë¸”ë¡œê·¸ ë°œê²¬")
        
        # ì‹¤ì œ ê°€ì ¸ì˜¬ ê°œìˆ˜ ê²°ì • (ìµœì†Œê°’)
        actual_count = min(total_count, available_total)
        
        if actual_count == 0:
            print("   âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            return []
        
        print(f"   ğŸ“¥ ìˆ˜ì§‘ ëª©í‘œ: {actual_count}ê°œ")
        
    except Exception as e:
        print(f"âŒ ì´ˆê¸° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []
    
    # 2ë‹¨ê³„: 100ê°œì”© ë‚˜ëˆ ì„œ ìš”ì²­
    max_per_request = 100
    requests_needed = (actual_count + max_per_request - 1) // max_per_request  # ì˜¬ë¦¼
    
    for page in range(requests_needed):
        start = page * max_per_request + 1
        
        # ë‚¨ì€ ê°œìˆ˜ ê³„ì‚°
        remaining = actual_count - len(all_blogs)
        if remaining <= 0:
            break
        
        # ì´ë²ˆ ìš”ì²­ì—ì„œ ê°€ì ¸ì˜¬ ê°œìˆ˜
        display = min(max_per_request, remaining)
        
        params = {
            "query": query,
            "display": display,
            "start": start,
            "sort": "sim"
        }
        
        try:
            print(f"   â³ ìš”ì²­ {page + 1}/{requests_needed}: start={start}, display={display}")
            
            response = requests.get(url, headers=headers, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            items = data.get("items", [])
            
            # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ì¶”ê°€
            new_count = 0
            for item in items:
                link = item.get("link", "")
                if link and link not in seen_links:
                    seen_links.add(link)
                    all_blogs.append(item)
                    new_count += 1
                    
                    # ëª©í‘œ ê°œìˆ˜ ë„ë‹¬í•˜ë©´ ì¤‘ë‹¨
                    if len(all_blogs) >= actual_count:
                        break
            
            print(f"      âœ… ìˆ˜ì§‘: {new_count}ê°œ (ëˆ„ì : {len(all_blogs)}/{actual_count}ê°œ)")
            
            # ëª©í‘œ ê°œìˆ˜ ë„ë‹¬í•˜ë©´ ë£¨í”„ ì¢…ë£Œ
            if len(all_blogs) >= actual_count:
                break
            
            # API ìš”ì²­ ê°„ê²© (ê³¼ë¶€í•˜ ë°©ì§€)
            if page < requests_needed - 1:
                time.sleep(0.1)
                
        except Exception as e:
            print(f"   âš ï¸  ìš”ì²­ {page + 1} ì‹¤íŒ¨: {e}")
            continue
    
    print(f"   âœ… ìµœì¢… ìˆ˜ì§‘: {len(all_blogs)}ê°œ (ì¤‘ë³µ ì œê±° ì™„ë£Œ)")
    return all_blogs


# ==================== ë¸”ë¡œê·¸ ë‚´ìš© í¬ë¡¤ë§ ====================

def crawl_blog_content(blog_url: str) -> str:
    """
    ë¸”ë¡œê·¸ ë³¸ë¬¸ í¬ë¡¤ë§
    
    Args:
        blog_url: ë¸”ë¡œê·¸ URL
    
    Returns:
        ë³¸ë¬¸ í…ìŠ¤íŠ¸
    """
    try:
        # User-Agent ì„¤ì •
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        
        response = requests.get(blog_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë³¸ë¬¸ ì¶”ì¶œ
        # iframe ë‚´ë¶€ ì ‘ê·¼ í•„ìš” (ì‹¤ì œë¡œëŠ” ë” ë³µì¡)
        content = soup.get_text(strip=True)
        
        return content
    except Exception as e:
        print(f"âš ï¸  í¬ë¡¤ë§ ì‹¤íŒ¨ ({blog_url}): {e}")
        return ""


# ==================== í‚¤ì›Œë“œ ì¶”ì¶œ ====================

def extract_keywords(text: str) -> List[str]:
    """
    í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    """
    # ì—…ì¢… í‚¤ì›Œë“œ
    industry_keywords = [
        "ìš”ë¦¬ì£¼ì ", "ìˆ ì§‘", "ì£¼ì ", "í˜¸í”„ì§‘", "í¬ì°¨", "ì´ìì¹´ì•¼", 
        "ì™€ì¸ë°”", "ì¹µí…Œì¼ë°”", "í", "ë°”", "ì¹´í˜", "ìŒì‹ì "
    ]
    
    # ì»¨ì…‰ í‚¤ì›Œë“œ
    concept_keywords = [
        "í—ŒíŒ…", "ë¯¸íŒ…", "ì†Œê°œíŒ…", "ë°ì´íŠ¸", "í˜¼ìˆ ", "ì¹œëª©", 
        "íšŒì‹", "ë‹¨ì²´", "ì¡°ìš©í•œ", "ì‹œë„ëŸ¬ìš´", "ë¶„ìœ„ê¸°"
    ]
    
    # ë§› í‚¤ì›Œë“œ
    taste_keywords = [
        "ë§›ìˆë‹¤", "ë§›ì—†ë‹¤", "ë‹¬ë‹¤", "ì§œë‹¤", "ë§¤ì½¤", "ê³ ì†Œ", 
        "ì‹ ì„ ", "ë°”ì‚­", "ë¶€ë“œëŸ½", "ì«„ê¹ƒ"
    ]
    
    # ì„œë¹„ìŠ¤ í‚¤ì›Œë“œ
    service_keywords = [
        "ì¹œì ˆ", "ë¶ˆì¹œì ˆ", "ë¹ ë¥´ë‹¤", "ëŠë¦¬ë‹¤", "ì„œë¹„ìŠ¤", 
        "ëŒ€ê¸°", "ì›¨ì´íŒ…", "ì˜ˆì•½"
    ]
    
    keywords = []
    text_lower = text.lower()
    
    for keyword_list in [industry_keywords, concept_keywords, taste_keywords, service_keywords]:
        for kw in keyword_list:
            if kw in text_lower:
                keywords.append(kw)
    
    return keywords


# ==================== ì—…ì¢…/ìƒê¶Œ ìë™ ì¶”ì¶œ ====================

def extract_industry_and_area(blogs: List[Dict]) -> tuple:
    """
    ë¸”ë¡œê·¸ì—ì„œ ì—…ì¢…ê³¼ ìƒê¶Œ ìë™ ì¶”ì¶œ
    
    Args:
        blogs: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        (ì—…ì¢…, ìƒê¶Œ)
    """
    industry_counter = Counter()
    area_counter = Counter()
    
    # ì—…ì¢… í‚¤ì›Œë“œ
    industry_map = {
        "ìš”ë¦¬ì£¼ì ": ["ìš”ë¦¬ì£¼ì ", "ì•ˆì£¼ì§‘"],
        "ì´ìì¹´ì•¼": ["ì´ìì¹´ì•¼", "ì•¼í‚¤í† ë¦¬"],
        "ìˆ ì§‘": ["ìˆ ì§‘", "ì£¼ì ", "í˜¸í”„ì§‘"],
        "ë°”": ["ë°”", "ì™€ì¸ë°”", "ì¹µí…Œì¼ë°”"],
        "ì¹´í˜": ["ì¹´í˜", "ë””ì €íŠ¸"],
    }
    
    # ìƒê¶Œ í‚¤ì›Œë“œ
    area_keywords = [
        "ê±´ëŒ€", "í™ëŒ€", "ê°•ë‚¨", "ì‹ ì´Œ", "ì´ëŒ€", "ì„±ìˆ˜", "ì ì‹¤",
        "ì´íƒœì›", "í•œë‚¨", "ì••êµ¬ì •", "ì²­ë‹´", "ê°€ë¡œìˆ˜ê¸¸",
        "ì‹ ì‚¬", "ë…¼í˜„", "ì—­ì‚¼", "ì„ ë¦‰"
    ]
    
    for blog in blogs:
        text = (blog.get("title", "") + " " + blog.get("description", "")).lower()
        
        # ì—…ì¢… ì¶”ì¶œ
        for industry, keywords in industry_map.items():
            for kw in keywords:
                if kw in text:
                    industry_counter[industry] += 1
        
        # ìƒê¶Œ ì¶”ì¶œ
        for area in area_keywords:
            if area in text:
                area_counter[area] += 1
    
    # ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ê²ƒ ì„ íƒ
    industry = industry_counter.most_common(1)[0][0] if industry_counter else "ìŒì‹ì "
    area = area_counter.most_common(1)[0][0] if area_counter else "ì•Œ ìˆ˜ ì—†ìŒ"
    
    return industry, area


# ==================== ê°€ê²Œ í”„ë¡œí•„ ìƒì„± ====================

def create_store_profile(store_name: str, blogs: List[Dict]) -> StoreProfile:
    """
    ë¸”ë¡œê·¸ì—ì„œ ê°€ê²Œ í”„ë¡œí•„ ìë™ ìƒì„±
    
    Args:
        store_name: ê°€ê²Œëª…
        blogs: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        StoreProfile
    """
    print(f"\nğŸ” [{store_name}] ë¸”ë¡œê·¸ ë¶„ì„ ì¤‘... (ì´ {len(blogs)}ê°œ)")
    
    # 1. ì—…ì¢…/ìƒê¶Œ ì¶”ì¶œ
    industry, area = extract_industry_and_area(blogs)
    print(f"   ğŸ“ ì—…ì¢…: {industry} | ìƒê¶Œ: {area}")
    
    # 2. í‚¤ì›Œë“œ ìˆ˜ì§‘
    all_keywords = []
    menu_counter = Counter()
    purpose_counter = Counter()
    atmosphere_counter = Counter()
    positive_count = 0
    
    # ìµœëŒ€ 100ê°œë§Œ ë¶„ì„ (ì†ë„ ìµœì í™”)
    analysis_limit = min(100, len(blogs))
    
    for blog in blogs[:analysis_limit]:
        text = blog.get("title", "") + " " + blog.get("description", "")
        keywords = extract_keywords(text)
        all_keywords.extend(keywords)
        
        # ë©”ë‰´ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´)
        if "ë©”ë‰´" in text or "ì¶”ì²œ" in text:
            # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NER í•„ìš”
            pass
        
        # ë°©ë¬¸ ëª©ì 
        if any(kw in text for kw in ["ë°ì´íŠ¸", "ì—°ì¸", "ì»¤í”Œ"]):
            purpose_counter["ë°ì´íŠ¸"] += 1
        if any(kw in text for kw in ["ì¹œêµ¬", "ì¹œëª©", "ëª¨ì„"]):
            purpose_counter["ì¹œëª©"] += 1
        if any(kw in text for kw in ["í˜¼ìˆ ", "í˜¼ì"]):
            purpose_counter["í˜¼ìˆ "] += 1
        if any(kw in text for kw in ["íšŒì‹", "ë‹¨ì²´", "íŒ€"]):
            purpose_counter["íšŒì‹"] += 1
        
        # ë¶„ìœ„ê¸°
        if "ì‹œë„ëŸ½" in text:
            atmosphere_counter["ì‹œë„ëŸ¬ì›€"] += 1
        if any(kw in text for kw in ["ì¡°ìš©", "ì•„ëŠ‘"]):
            atmosphere_counter["ì¡°ìš©í•¨"] += 1
        if "ë„“" in text:
            atmosphere_counter["ë„“ìŒ"] += 1
        
        # ê¸ì •/ë¶€ì •
        if any(kw in text for kw in ["ì¢‹", "ë§›ìˆ", "ì¶”ì²œ", "ìµœê³ "]):
            positive_count += 1
    
    # 3. ì»¨ì…‰ ì¶”ì¶œ
    keyword_freq = Counter(all_keywords)
    
    concept = "ì¼ë°˜"
    if keyword_freq.get("í—ŒíŒ…", 0) > 3:
        concept = "í—ŒíŒ…í¬ì°¨"
    elif keyword_freq.get("ë°ì´íŠ¸", 0) > 5:
        concept = "ë°ì´íŠ¸ ëª…ì†Œ"
    elif keyword_freq.get("í˜¼ìˆ ", 0) > 3:
        concept = "í˜¼ìˆ ì§‘"
    
    # 4. ê°€ê²©ëŒ€ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´)
    price_range = "2-3ë§Œì›ëŒ€"  # ê¸°ë³¸ê°’
    
    # 5. í”„ë¡œí•„ ìƒì„±
    profile = StoreProfile(
        name=store_name,
        industry=industry,
        area=area,
        concept=concept,
        target_customers=["20ëŒ€", "ëŒ€í•™ìƒ"],  # ìƒê¶Œ ê¸°ë°˜ ì¶”ì •
        signature_menus=menu_counter.most_common(3),
        price_range=price_range,
        atmosphere_keywords=[k for k, v in atmosphere_counter.most_common(3)],
        visit_purposes=dict(purpose_counter),
        peak_times=["ê¸ˆìš”ì¼ ì €ë…", "ì£¼ë§"],
        foot_traffic="ìƒ" if "ê±´ëŒ€" in area or "í™ëŒ€" in area else "ì¤‘",
        competition_level="ë†’ìŒ",
        total_blog_posts=len(blogs),
        positive_ratio=positive_count / analysis_limit if analysis_limit > 0 else 0,
        avg_rating=4.2  # ì‹¤ì œë¡œëŠ” ë³„ì  íŒŒì‹± í•„ìš”
    )
    
    print(f"   âœ… í”„ë¡œí•„ ìƒì„± ì™„ë£Œ!")
    print(f"      ì»¨ì…‰: {concept}")
    print(f"      ì£¼ìš” ë°©ë¬¸ ëª©ì : {dict(purpose_counter.most_common(3))}")
    print(f"      ê¸ì • ë¹„ìœ¨: {profile.positive_ratio:.1%}")
    
    return profile


# ==================== ë©”ì¸ í•¨ìˆ˜ ====================

def analyze_store_from_blog(store_name: str) -> StoreProfile:
    """
    ë„¤ì´ë²„ ë¸”ë¡œê·¸ì—ì„œ ê°€ê²Œ ë¶„ì„
    
    Args:
        store_name: ê°€ê²Œëª…
    
    Returns:
        StoreProfile
    """
    print("="*60)
    print(f"ğŸ” ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë¶„ì„ ì‹œì‘: {store_name}")
    print("="*60)
    
    # 1. ë¸”ë¡œê·¸ ê²€ìƒ‰ (ìµœëŒ€ 200ê°œ, ì¤‘ë³µ ì œê±°)
    blogs = search_naver_blog(store_name, total_count=200)
    
    if not blogs:
        print("âŒ ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return None
    
    print(f"ğŸ“Š ìµœì¢… ìˆ˜ì§‘: {len(blogs)}ê°œ ë¸”ë¡œê·¸")
    
    # 2. ê°€ê²Œ í”„ë¡œí•„ ìƒì„±
    profile = create_store_profile(store_name, blogs)
    
    return profile


# ==================== ìƒê¶Œ ë¶„ì„ (ë³´ì¡°) ====================

def analyze_market_context(profile: StoreProfile) -> Dict:
    """
    ìƒê¶Œ ë§¥ë½ ë¶„ì„ (AI ë³´ì¡°)
    
    Args:
        profile: ê°€ê²Œ í”„ë¡œí•„
    
    Returns:
        ìƒê¶Œ ë¶„ì„ ê²°ê³¼
    """
    # ìƒê¶Œ íŠ¹ì„± DB (ê°„ë‹¨í•œ ë£° ê¸°ë°˜)
    market_db = {
        "ê±´ëŒ€": {
            "type": "ëŒ€í•™ê°€",
            "age": "20ëŒ€ ì¤‘ì‹¬",
            "peak": "í•™ê¸°ì¤‘ > ë°©í•™",
            "íŠ¹ì§•": "ìœ ë™ì¸êµ¬ ë§ìŒ, ê²½ìŸ ì¹˜ì—´"
        },
        "í™ëŒ€": {
            "type": "ì ŠìŒì˜ê±°ë¦¬",
            "age": "20-30ëŒ€",
            "peak": "ì£¼ë§ ì €ë…",
            "íŠ¹ì§•": "íŠ¸ë Œë””, ë†’ì€ ì„ëŒ€ë£Œ"
        },
        "ê°•ë‚¨": {
            "type": "ë¹„ì¦ˆë‹ˆìŠ¤ + ìœ í¥",
            "age": "30ëŒ€ ì¤‘ì‹¬",
            "peak": "í‰ì¼ ì €ë…",
            "íŠ¹ì§•": "ê³ ì†Œë“ì¸µ, ê³ ê°€ê²©"
        }
    }
    
    context = market_db.get(profile.area, {
        "type": "ì¼ë°˜ ìƒê¶Œ",
        "age": "ë‹¤ì–‘",
        "peak": "ì €ë… ì‹œê°„ëŒ€",
        "íŠ¹ì§•": "ì •ë³´ ë¶€ì¡±"
    })
    
    return {
        "area": profile.area,
        "industry": profile.industry,
        "concept": profile.concept,
        "market_type": context["type"],
        "target_age": context["age"],
        "peak_season": context["peak"],
        "íŠ¹ì§•": context["íŠ¹ì§•"],
        "ê²½ìŸê°•ë„": profile.competition_level,
        "ìœ ë™ì¸êµ¬": profile.foot_traffic
    }


# ==================== í…ŒìŠ¤íŠ¸ ====================

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    store_name = "ì£¼ë‹¤ë°© ê±´ëŒ€ì "
    
    # ë¸”ë¡œê·¸ ë¶„ì„
    profile = analyze_store_from_blog(store_name)
    
    if profile:
        print("\n" + "="*60)
        print("ğŸ“Š ë¶„ì„ ê²°ê³¼")
        print("="*60)
        print(f"ê°€ê²Œëª…: {profile.name}")
        print(f"ì—…ì¢…: {profile.industry}")
        print(f"ìƒê¶Œ: {profile.area}")
        print(f"ì»¨ì…‰: {profile.concept}")
        print(f"ì£¼ìš” ê³ ê°: {', '.join(profile.target_customers)}")
        print(f"ë¶„ìœ„ê¸°: {', '.join(profile.atmosphere_keywords)}")
        print(f"ë°©ë¬¸ ëª©ì : {profile.visit_purposes}")
        print(f"ë¸”ë¡œê·¸ ìˆ˜: {profile.total_blog_posts}ê°œ")
        print(f"ê¸ì • ë¹„ìœ¨: {profile.positive_ratio:.1%}")
        
        # ìƒê¶Œ ë¶„ì„
        print("\n" + "="*60)
        print("ğŸ—ºï¸  ìƒê¶Œ ë¶„ì„")
        print("="*60)
        market = analyze_market_context(profile)
        for k, v in market.items():
            print(f"   {k}: {v}")